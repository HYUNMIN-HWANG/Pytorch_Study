{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PYTORCH MODULE\r\n",
    "- [pytorch document](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\r\n",
    "- [How to Use PyTorch](https://greeksharifa.github.io/pytorch/2018/11/10/pytorch-usage-03-How-to-Use-PyTorch/#pytorch-model)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.nn.Module"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "class Model(nn.Module): \r\n",
    "    def __init__(self):                     \r\n",
    "        # 모델에 사용될 module을 정의\r\n",
    "        super(Model, self).__init__()\r\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\r\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\r\n",
    "        self.flat = nn.Flatten(20)\r\n",
    "    \r\n",
    "    def forward(self, x) :                  \r\n",
    "        # train 중 forward 계산할 때 모델에서 작동하는 계산을 정의 (__init__에서 정의한 모듈 그래도 사용), \r\n",
    "        # backward계산은 나중에 backward() 호출하면 계산해준다.\r\n",
    "        x = F.relu(self.conv1)\r\n",
    "        x = F.relu(self.conv2(x))\r\n",
    "        return F.relu(self.flat(x))\r\n",
    "\r\n",
    "model = Model()\r\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "# add_module(name, module) : Adds a child module to the current module.\r\n",
    "dense_layer = nn.Linear(20, 32)\r\n",
    "model.add_module('flatten', dense_layer)\r\n",
    "model"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 129
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "source": [
    "# apply(fn) : Applies fn recursively to every submodule (as returned by .children()) as well as self.\r\n",
    "# nitializing the parameters of a model 할 때 많이 사용함\r\n",
    "\r\n",
    "@torch.no_grad()\r\n",
    "def init_weight(m):\r\n",
    "    print(m)\r\n",
    "    if type(m) == nn.Linear :\r\n",
    "        m.weight.fill_(1.0) # weight를 1.0으로 초기화\r\n",
    "        print(m.weight)\r\n",
    "        print(\"><><><><><\")\r\n",
    "\r\n",
    "net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\r\n",
    "net.apply(init_weight)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "><><><><><\n",
      "Linear(in_features=2, out_features=2, bias=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "><><><><><\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "source": [
    "# children() : Returns an iterator over immediate children modules.\r\n",
    "\r\n",
    "for idx, layer in enumerate(model.children()):\r\n",
    "    print(idx, \"->\", layer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 -> Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "1 -> Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "2 -> Flatten(start_dim=20, end_dim=-1)\n",
      "3 -> Linear(in_features=20, out_features=32, bias=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "# modules() : Returns an iterator over all modules in the network.\r\n",
    "for idx, layer in enumerate(model.modules()):\r\n",
    "    print(idx, \"->\", layer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0 -> Model(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
      "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
      ")\n",
      "1 -> Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "2 -> Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "3 -> Flatten(start_dim=20, end_dim=-1)\n",
      "4 -> Linear(in_features=20, out_features=32, bias=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# named_buffers() : 이름까지 반환 \r\n",
    "# Returns an iterator over immediate children modules, yielding both the name of the module as well as the module itself.\r\n",
    "\r\n",
    "for name, layer in model.named_children():\r\n",
    "    print(name, \":\", layer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "conv1 : Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "conv2 : Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "flat : Flatten(start_dim=20, end_dim=-1)\n",
      "flatten : Linear(in_features=20, out_features=32, bias=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "source": [
    "# parameters(recurse=True) : Returns an iterator over module parameters.\r\n",
    "\r\n",
    "for param in model.parameters():\r\n",
    "    print(type(param), param.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 1, 5, 5])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20, 20, 5, 5])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([20])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32, 20])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([32])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "source": [
    "# state_dict(destination=None, prefix='', keep_vars=False) 모델 저장\r\n",
    "# Returns a dictionary containing a whole state of the module.\r\n",
    "model.state_dict()\r\n",
    "model.state_dict().keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'flatten.weight', 'flatten.bias'])"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "# load_state_dict(state_dict, strict=True) \r\n",
    "# Copies parameters and buffers from state_dict into this module and its descendants.\r\n",
    "# If strict is True, then the keys of state_dict must exactly match the keys returned by this module’s state_dict() function.\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "source": [
    "# cuda(device=None) Moves all model parameters and buffers to the GPU.\r\n",
    "# it should be called before constructing optimizer if the module will live on GPU while being optimized.\r\n",
    "model.cuda()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# eval() : Sets the module in evaluation mode.\r\n",
    "# This is equivalent with self.train(False).\r\n",
    "\r\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "# train(mode=True) : Sets the module in training mode.\r\n",
    "model.train()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "# to(*args, **kwargs) : Moves and/or casts the parameters and buffers.\r\n",
    "\r\n",
    "# dtype (torch.dtype) : the desired floating point or complex dtype of the parameters and buffers in this module\r\n",
    "model.to(torch.double) \r\n",
    "\r\n",
    "# device (torch.device) : the desired device of the parameters and buffers in this module\r\n",
    "gpu1 = torch.device(\"cuda\")\r\n",
    "model.to(gpu1, dtype=torch.half, non_blocking=True) \r\n",
    "\r\n",
    "cpu = torch.device(\"cpu\")\r\n",
    "model.to(cpu)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "source": [
    "# requires_grad_(requires_grad=True) : Change if autograd should record operations on parameters in this module.\r\n",
    "model.requires_grad_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<bound method Module.requires_grad_ of Model(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (flat): Flatten(start_dim=20, end_dim=-1)\n",
       "  (flatten): Linear(in_features=20, out_features=32, bias=True)\n",
       ")>"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "source": [
    "linear = nn.Linear(2, 2)\r\n",
    "linear.weight"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5519, -0.2719],\n",
       "        [ 0.2158,  0.1707]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.5 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "00e1617900caed98bbe9cd2040dc61f2a95a81109ddebe3a289f146b162564c9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}